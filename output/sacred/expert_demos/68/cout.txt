INFO - expert_demos - Running command 'rollouts_and_policy'
INFO - expert_demos - Started run with ID "68"
Logging to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/rl
Using cuda device
INFO - root - Saved policy to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/policies/000000010000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 480       |
|    ep_rew_mean     | -4.76e+03 |
| time/              |           |
|    fps             | 6.29e+03  |
|    iterations      | 1         |
|    time_elapsed    | 2         |
|    total_timesteps | 1.64e+04  |
----------------------------------
INFO - root - Saved policy to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/policies/000000020000
INFO - root - Saved policy to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/policies/000000030000
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.28e+03  |
|    ep_rew_mean          | -1.05e+04 |
| time/                   |           |
|    fps                  | 2.22e+03  |
|    iterations           | 2         |
|    time_elapsed         | 14        |
|    total_timesteps      | 3.28e+04  |
| train/                  |           |
|    approx_kl            | 0.0192    |
|    clip_fraction        | 0.242     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.37     |
|    explained_variance   | -3.4e+05  |
|    learning_rate        | 0.0003    |
|    loss                 | 2.16e+04  |
|    n_updates            | 10        |
|    policy_gradient_loss | -0.0348   |
|    value_loss           | 3.53e+04  |
---------------------------------------
INFO - root - Saved policy to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/policies/000000040000
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.52e+03  |
|    ep_rew_mean          | -1.22e+04 |
| time/                   |           |
|    fps                  | 1.81e+03  |
|    iterations           | 3         |
|    time_elapsed         | 27        |
|    total_timesteps      | 4.92e+04  |
| train/                  |           |
|    approx_kl            | 0.0111    |
|    clip_fraction        | 0.232     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.33     |
|    explained_variance   | -8.65e+05 |
|    learning_rate        | 0.0003    |
|    loss                 | 2.99e+03  |
|    n_updates            | 20        |
|    policy_gradient_loss | -0.0304   |
|    value_loss           | 7.65e+03  |
---------------------------------------
INFO - root - Saved policy to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/policies/000000050000
INFO - root - Saved policy to output/expert_demos/CliffWalking-v0/20210801_133243_3b2d22/policies/000000060000
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.14e+03  |
|    ep_rew_mean          | -1.37e+04 |
| time/                   |           |
|    fps                  | 1.65e+03  |
|    iterations           | 4         |
|    time_elapsed         | 39        |
|    total_timesteps      | 6.55e+04  |
| train/                  |           |
|    approx_kl            | 0.0115    |
|    clip_fraction        | 0.139     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.29     |
|    explained_variance   | -84.2     |
|    learning_rate        | 0.0003    |
|    loss                 | 458       |
|    n_updates            | 30        |
|    policy_gradient_loss | -0.0188   |
|    value_loss           | 1.4e+03   |
---------------------------------------
det_policy_as_dict_only_discr_sp 
  {0: 0, 1: 3, 2: 0, 3: 3, 4: 0, 5: 0, 6: 3, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0}
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
out_dict_unstacked  defaultdict(<class 'list'>, {'obs': [36, 24], 'acts': [0], 'rews': [-1.0], 'infos': [{'prob': 1.0}]})
